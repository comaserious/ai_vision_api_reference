{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "react agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# 현재 멀티모달 제공하는 모델은 3가지지\n",
    "\n",
    "import base64\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ImageDescription(BaseModel):\n",
    "    category : str = Field(description = \"이미지의 카테고리. 4가지 카테고리 : ['figure', 'chart', 'table', 'equation']\")\n",
    "    description : str = Field(description = \"이미지의 설명\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path : str):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_path = \"C:\\\\test_test\\\\response_rate_of_image_description\\\\data\\\\equation.png\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "base64_image = encode_image(image_path)\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4.1\" , temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from glom import glom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_image_description(image_path : str):\n",
    "    \"\"\"\n",
    "    이미지 경로를 통해서 이미지 종류('figure', 'chart', 'table', 'equation')와 설명을 반환하는 툴\n",
    "    \"\"\"\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    ext  = os.path.splitext(image_path)[1]\n",
    "\n",
    "    client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    message_list = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"주어진 이미지를 분석하세요. 이미지 종류('figure', 'chart', 'table', 'equation')와 설명을 반환하세요. 표의 경우 담겨있는 정보를 생략하지 말고 전부 일목요연하게 제공하세요. 설명의 경우 마크다운으로 작성하세요요\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/{ext};base64,{base64_image}\",\n",
    "                    \"detail\": \"high\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.responses.parse(\n",
    "        model = \"gpt-4.1\",\n",
    "        input = message_list,\n",
    "        text_format=ImageDescription\n",
    "    )\n",
    "\n",
    "    re_output = response.output_parsed\n",
    "\n",
    "    category = glom(re_output, 'category', default = None)\n",
    "    description = glom(re_output, 'description', default = None)\n",
    "\n",
    "    return category, description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "async def upstage_parser(image_path : str):\n",
    "    \"\"\"\n",
    "    이미지 경로를 통해서 이미지 종류('chart', 'table', 'equation')인 이미지를 markdown 형태로 반환하는 툴\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\"Authorization\" : f\"Bearer {UPSTAGE_API_KEY}\"}\n",
    "\n",
    "    files = {\"document\" : open(image_path, 'rb')}\n",
    "\n",
    "    config = {\n",
    "        \n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        \"https://api.upstage.ai/v1/document-ai/document-parse\",\n",
    "        headers = headers,\n",
    "        data = config,\n",
    "        files = files\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "\n",
    "        markdown_content = glom(response_json, 'content.markdown', default = None)\n",
    "\n",
    "        return markdown_content\n",
    "\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content = f\"\"\"\n",
    "    image_path {image_path}\n",
    "\n",
    "    당신은 제공받은 이미지 경로를 이용하여 이미지 카테고리('figure', 'chart', 'table', 'equation')과 설명을 이용하여 이미지를 분석하는 봇입니다.\n",
    "\n",
    "    get_image_description 툴을 이용하여 이미지 카테고리와 이미지 설명을 반환받으세요\n",
    "\n",
    "    제공받은 설명을 완벽한 마크다운 형태로 리포맷팅 하세요.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "tools = [get_image_description]\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4.1\", temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    prompt = system_message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "inputs = {\n",
    "    \"messages\" : [\n",
    "        (\"user\", \"주어진 이미지를 분석하세요\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=10\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mtools\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "[\"figure\", \"이 이미지는 활짝 웃으며 춤을 추는 하마의 귀여운 캐릭터 일러스트입니다. 하마는 한 발로 서서 팔과 다리를 활짝 벌린 채, 매우 즐거운 표정을 하고 있습니다. 배경은 부드러운 색감의 자연 풍경으로 따뜻한 분위기를 연출합니다. 이 이미지는 유쾌하고 생동감 넘치는 분위기를 전달합니다.\"]\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## 이미지 분석 결과\n",
      "\n",
      "- **카테고리:** Figure\n",
      "\n",
      "- **설명:**  \n",
      "  이 이미지는 활짝 웃으며 춤을 추는 하마의 귀여운 캐릭터 일러스트입니다. 하마는 한 발로 서서 팔과 다리를 활짝 벌린 채, 매우 즐거운 표정을 하고 있습니다. 배경은 부드러운 색감의 자연 풍경으로 따뜻한 분위기를 연출합니다. 이 이미지는 유쾌하고 생동감 넘치는 분위기를 전달합니다.Time taken: 11.24609637260437 seconds\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "stream_graph(agent, inputs, config)\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-module",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
