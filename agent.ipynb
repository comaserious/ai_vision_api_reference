{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "react agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# í˜„ì¬ ë©€í‹°ëª¨ë‹¬ ì œê³µí•˜ëŠ” ëª¨ë¸ì€ 3ê°€ì§€ì§€\n",
    "\n",
    "import base64\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ImageDescription(BaseModel):\n",
    "    category : str = Field(description = \"ì´ë¯¸ì§€ì˜ ì¹´í…Œê³ ë¦¬. 4ê°€ì§€ ì¹´í…Œê³ ë¦¬ : ['figure', 'chart', 'table', 'equation']\")\n",
    "    description : str = Field(description = \"ì´ë¯¸ì§€ì˜ ì„¤ëª…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path : str):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_path = \"C:\\\\test_test\\\\response_rate_of_image_description\\\\data\\\\equation.png\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "base64_image = encode_image(image_path)\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4.1\" , temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from glom import glom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_image_description(image_path : str):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í†µí•´ì„œ ì´ë¯¸ì§€ ì¢…ë¥˜('figure', 'chart', 'table', 'equation')ì™€ ì„¤ëª…ì„ ë°˜í™˜í•˜ëŠ” íˆ´\n",
    "    \"\"\"\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    ext  = os.path.splitext(image_path)[1]\n",
    "\n",
    "    client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    message_list = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"ì£¼ì–´ì§„ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì„¸ìš”. ì´ë¯¸ì§€ ì¢…ë¥˜('figure', 'chart', 'table', 'equation')ì™€ ì„¤ëª…ì„ ë°˜í™˜í•˜ì„¸ìš”. í‘œì˜ ê²½ìš° ë‹´ê²¨ìˆëŠ” ì •ë³´ë¥¼ ìƒëµí•˜ì§€ ë§ê³  ì „ë¶€ ì¼ëª©ìš”ì—°í•˜ê²Œ ì œê³µí•˜ì„¸ìš”. ì„¤ëª…ì˜ ê²½ìš° ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”ìš”\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/{ext};base64,{base64_image}\",\n",
    "                    \"detail\": \"high\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.responses.parse(\n",
    "        model = \"gpt-4.1\",\n",
    "        input = message_list,\n",
    "        text_format=ImageDescription\n",
    "    )\n",
    "\n",
    "    re_output = response.output_parsed\n",
    "\n",
    "    category = glom(re_output, 'category', default = None)\n",
    "    description = glom(re_output, 'description', default = None)\n",
    "\n",
    "    return category, description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "async def upstage_parser(image_path : str):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í†µí•´ì„œ ì´ë¯¸ì§€ ì¢…ë¥˜('chart', 'table', 'equation')ì¸ ì´ë¯¸ì§€ë¥¼ markdown í˜•íƒœë¡œ ë°˜í™˜í•˜ëŠ” íˆ´\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\"Authorization\" : f\"Bearer {UPSTAGE_API_KEY}\"}\n",
    "\n",
    "    files = {\"document\" : open(image_path, 'rb')}\n",
    "\n",
    "    config = {\n",
    "        \n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        \"https://api.upstage.ai/v1/document-ai/document-parse\",\n",
    "        headers = headers,\n",
    "        data = config,\n",
    "        files = files\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "\n",
    "        markdown_content = glom(response_json, 'content.markdown', default = None)\n",
    "\n",
    "        return markdown_content\n",
    "\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content = f\"\"\"\n",
    "    image_path {image_path}\n",
    "\n",
    "    ë‹¹ì‹ ì€ ì œê³µë°›ì€ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì¹´í…Œê³ ë¦¬('figure', 'chart', 'table', 'equation')ê³¼ ì„¤ëª…ì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ë´‡ì…ë‹ˆë‹¤.\n",
    "\n",
    "    get_image_description íˆ´ì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì¹´í…Œê³ ë¦¬ì™€ ì´ë¯¸ì§€ ì„¤ëª…ì„ ë°˜í™˜ë°›ìœ¼ì„¸ìš”\n",
    "\n",
    "    ì œê³µë°›ì€ ì„¤ëª…ì„ ì™„ë²½í•œ ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ë¦¬í¬ë§·íŒ… í•˜ì„¸ìš”.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "tools = [get_image_description]\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4.1\", temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    prompt = system_message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "inputs = {\n",
    "    \"messages\" : [\n",
    "        (\"user\", \"ì£¼ì–´ì§„ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì„¸ìš”\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=10\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "[\"figure\", \"ì´ ì´ë¯¸ì§€ëŠ” í™œì§ ì›ƒìœ¼ë©° ì¶¤ì„ ì¶”ëŠ” í•˜ë§ˆì˜ ê·€ì—¬ìš´ ìºë¦­í„° ì¼ëŸ¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. í•˜ë§ˆëŠ” í•œ ë°œë¡œ ì„œì„œ íŒ”ê³¼ ë‹¤ë¦¬ë¥¼ í™œì§ ë²Œë¦° ì±„, ë§¤ìš° ì¦ê±°ìš´ í‘œì •ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë°°ê²½ì€ ë¶€ë“œëŸ¬ìš´ ìƒ‰ê°ì˜ ìì—° í’ê²½ìœ¼ë¡œ ë”°ëœ»í•œ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•©ë‹ˆë‹¤. ì´ ì´ë¯¸ì§€ëŠ” ìœ ì¾Œí•˜ê³  ìƒë™ê° ë„˜ì¹˜ëŠ” ë¶„ìœ„ê¸°ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\"]\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼\n",
      "\n",
      "- **ì¹´í…Œê³ ë¦¬:** Figure\n",
      "\n",
      "- **ì„¤ëª…:**  \n",
      "  ì´ ì´ë¯¸ì§€ëŠ” í™œì§ ì›ƒìœ¼ë©° ì¶¤ì„ ì¶”ëŠ” í•˜ë§ˆì˜ ê·€ì—¬ìš´ ìºë¦­í„° ì¼ëŸ¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. í•˜ë§ˆëŠ” í•œ ë°œë¡œ ì„œì„œ íŒ”ê³¼ ë‹¤ë¦¬ë¥¼ í™œì§ ë²Œë¦° ì±„, ë§¤ìš° ì¦ê±°ìš´ í‘œì •ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë°°ê²½ì€ ë¶€ë“œëŸ¬ìš´ ìƒ‰ê°ì˜ ìì—° í’ê²½ìœ¼ë¡œ ë”°ëœ»í•œ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•©ë‹ˆë‹¤. ì´ ì´ë¯¸ì§€ëŠ” ìœ ì¾Œí•˜ê³  ìƒë™ê° ë„˜ì¹˜ëŠ” ë¶„ìœ„ê¸°ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.Time taken: 11.24609637260437 seconds\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "stream_graph(agent, inputs, config)\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-module",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
