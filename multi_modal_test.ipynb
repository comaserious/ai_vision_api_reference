{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import base64, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"C:\\\\test_test\\\\response_rate_of_image_description\\\\image.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ImageDescription(BaseModel):\n",
    "    category : str = Field(description = \"이미지의 카테고리. 4가지 카테고리 : ['figure', 'chart', 'table', 'equation']\")\n",
    "    description : str = Field(description = \"이미지의 설명\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path : str):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "ext = os.path.splitext(image_path)[1].replace('.','')\n",
    "\n",
    "message_list = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"주어진 이미지를 분석하세요. 이미지 종류('figure', 'chart', 'table', 'equation')와 설명을 반환하세요. 표의 경우 담겨있는 정보를 생략하지 말고 전부 일목요연하게 제공하세요. 설명의 경우 마크다운으로 작성하세요요\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/{ext};base64,{base64_image}\",\n",
    "                    \"detail\": \"high\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.parse(\n",
    "        model = \"gpt-4.1\",\n",
    "        input = message_list,\n",
    "        text_format=ImageDescription\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category='figure' description='이 이미지는 만화 스타일로 그려진, 활짝 웃으며 춤을 추는 듯한 하마를 묘사하고 있습니다. 하마는 밝은 색조와 부드러운 터치로 표현되어 있으며, 배경은 따뜻한 색상의 식물 무늬로 이루어져 부드럽고 아늑한 분위기를 연출합니다. 하마는 한쪽 다리를 들고 두 팔을 크게 벌리며 환하게 웃고 있어, 유쾌하고 생동감 넘치는 모습을 나타냅니다.'\n"
     ]
    }
   ],
   "source": [
    "print(response.output_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_list = [\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\" : [\n",
    "            {\n",
    "                \"type\" : \"image\",\n",
    "                \"source\" : {\n",
    "                    \"type\" : \"base64\",\n",
    "                    \"media_type\" : \"image/png\",\n",
    "                    \"data\" : base64_image\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\" : \"text\",\n",
    "                \"text\" : \"Describe this image.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "message = client.messages.create(\n",
    "    model = \"claude-sonnet-4-20250514\",\n",
    "    max_tokens = 1024,\n",
    "    messages =message_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message(id='msg_01A9uAhUfQaYS2sJhd9MTC8v', content=[TextBlock(citations=None, text=\"This is a charming cartoon illustration of a cheerful hippopotamus in a dynamic, joyful pose. The hippo appears to be dancing or celebrating, with its arms outstretched and mouth wide open in what looks like laughter or singing. The character has a round, pudgy body typical of cartoon hippos, with small ears and a big smile showing its teeth.\\n\\nThe artwork is rendered in warm, golden-brown tones that give it a cozy, friendly atmosphere. The hippo is depicted against a textured background with swirling patterns that complement the warm color palette. The illustration style is smooth and polished, with soft shading and highlights that give the character dimension and personality.\\n\\nThe overall mood of the image is very positive and energetic, capturing a sense of happiness and exuberance through the hippo's animated pose and expression.\", type='text')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=1385, output_tokens=184, service_tier='standard'))\n"
     ]
    }
   ],
   "source": [
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-genai\n",
      "  Downloading google_genai-1.20.0-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from google-genai) (4.8.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from google-genai) (2.39.0)\n",
      "Collecting httpx<1.0.0,>=0.28.1 (from google-genai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from google-genai) (2.10.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from google-genai) (2.32.3)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from google-genai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\com-nmoim\\miniforge3\\envs\\graph-module\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
      "Downloading google_genai-1.20.0-py3-none-any.whl (203 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Installing collected packages: httpx, google-genai\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.2\n",
      "    Uninstalling httpx-0.27.2:\n",
      "      Successfully uninstalled httpx-0.27.2\n",
      "Successfully installed google-genai-1.20.0 httpx-0.28.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "embedchain 0.1.128 requires langchain-openai<0.3.0,>=0.2.1, but you have langchain-openai 0.3.14 which is incompatible.\n",
      "litellm 1.60.2 requires httpx<0.28.0,>=0.23.0, but you have httpx 0.28.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash-preview-04-17\",\n",
    "    contents = [\n",
    "        types.Part.from_bytes(\n",
    "            data = base64_image,\n",
    "            mime_type = \"image/png\"\n",
    "        ),\n",
    "        'Describe this image.'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A charming illustration depicts a chubby cartoon hippo joyfully dancing. The hippo, rendered in warm shades of brown with visible sketch lines, is balanced on one leg, with the other lifted slightly. Its arms are wide open and raised high, as if mid-leap or twirl. The hippo's head is tilted back slightly, eyes closed with a beaming, wide-open mouth revealing its teeth and tongue, conveying a sense of pure happiness and abandon. A tiny tail is visible in the back. The background is a soft, muted wash of earthy tones, including yellows, browns, and hints of green, with faint, blurry, sketchy shapes suggesting abstract foliage or a natural, organic setting. The overall style is whimsical and cheerful, reminiscent of a children's book illustration.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.0-flash\",\n",
    "    contents = [\n",
    "        types.Part.from_bytes(\n",
    "            data = base64_image,\n",
    "            mime_type = \"image/png\"\n",
    "        ),\n",
    "        'Describe this image.'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a description of the image:\n",
      "\n",
      "A cartoon hippopotamus is happily dancing. It is brown and stands on its left leg with the right leg raised slightly. The hippo has both arms raised as well. It has a wide open mouth with visible teeth, and closed eyes. The background is a soft, blurred mix of yellows, browns, and greens, suggesting a natural or forest-like environment. The style is reminiscent of a digital painting with textured shading.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini GPT 스타일일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_list = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"주어진 이미지를 분석하세요. 이미지 종류('figure', 'chart', 'table', 'equation')와 설명을 반환하세요. 표의 경우 담겨있는 정보를 생략하지 말고 전부 일목요연하게 제공하세요. 설명의 경우 마크다운으로 작성하세요요\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/{ext};base64,{base64_image}\",\n",
    "                    \"detail\": \"high\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gemini-2.5-flash-preview-04-17\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What is in this image?\",\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\":  f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image contains a cartoon-style drawing of a cheerful hippo. The hippo is standing on one leg, with its arms outstretched and a wide open, laughing mouth, suggesting it is dancing or cheering happily. The background is a warm, sketched style.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "XAI_API_KEY = os.getenv(\"XAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=XAI_API_KEY,\n",
    "    base_url=\"https://api.x.ai/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"grok-2-vision-latest\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What is in this image?\",\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\":  f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a cartoon-style hippopotamus with a joyful expression. The hippo is standing on one leg with its arms raised, appearing to be in a happy or celebratory pose. The background is a warm, earthy tone, suggesting a natural or jungle setting. The overall mood of the image is cheerful and lighthearted.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Mistral()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"What's in this image?\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": f\"data:image/jpeg;base64,{base64_image}\" \n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for Unmarshaller\nbody.0.user.content.str\n  Input should be a valid string [type=string_type, input_value=[{'type': 'text', 'text':...6W1uAAAAAElFTkSuQmCC'}}], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type\nbody.0.user.content.list[tagged-union[ImageURLChunk,DocumentURLChunk,TextChunk,ReferenceChunk]].1.image_url.image_url.ImageURL.url\n  Field required [type=missing, input_value={'image_url': 'data:image...Nf6W1uAAAAAElFTkSuQmCC'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nbody.0.user.content.list[tagged-union[ImageURLChunk,DocumentURLChunk,TextChunk,ReferenceChunk]].1.image_url.image_url.str\n  Input should be a valid string [type=string_type, input_value={'image_url': 'data:image...Nf6W1uAAAAAElFTkSuQmCC'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpixtral-12b-2409\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_list\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\COM-NMOIM\\miniforge3\\envs\\graph-module\\Lib\\site-packages\\mistralai\\chat.py:176\u001b[39m, in \u001b[36mChat.complete\u001b[39m\u001b[34m(self, model, messages, temperature, top_p, max_tokens, stream, stop, random_seed, response_format, tools, tool_choice, presence_penalty, frequency_penalty, n, prediction, parallel_tool_calls, prompt_mode, safe_prompt, retries, server_url, timeout_ms, http_headers)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    166\u001b[39m     base_url = \u001b[38;5;28mself\u001b[39m._get_url(base_url, url_variables)\n\u001b[32m    168\u001b[39m request = models.ChatCompletionRequest(\n\u001b[32m    169\u001b[39m     model=model,\n\u001b[32m    170\u001b[39m     temperature=temperature,\n\u001b[32m    171\u001b[39m     top_p=top_p,\n\u001b[32m    172\u001b[39m     max_tokens=max_tokens,\n\u001b[32m    173\u001b[39m     stream=stream,\n\u001b[32m    174\u001b[39m     stop=stop,\n\u001b[32m    175\u001b[39m     random_seed=random_seed,\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     messages=\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_pydantic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mList\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    177\u001b[39m     response_format=utils.get_pydantic_model(\n\u001b[32m    178\u001b[39m         response_format, Optional[models.ResponseFormat]\n\u001b[32m    179\u001b[39m     ),\n\u001b[32m    180\u001b[39m     tools=utils.get_pydantic_model(tools, OptionalNullable[List[models.Tool]]),\n\u001b[32m    181\u001b[39m     tool_choice=utils.get_pydantic_model(\n\u001b[32m    182\u001b[39m         tool_choice, Optional[models.ChatCompletionRequestToolChoice]\n\u001b[32m    183\u001b[39m     ),\n\u001b[32m    184\u001b[39m     presence_penalty=presence_penalty,\n\u001b[32m    185\u001b[39m     frequency_penalty=frequency_penalty,\n\u001b[32m    186\u001b[39m     n=n,\n\u001b[32m    187\u001b[39m     prediction=utils.get_pydantic_model(\n\u001b[32m    188\u001b[39m         prediction, Optional[models.Prediction]\n\u001b[32m    189\u001b[39m     ),\n\u001b[32m    190\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    191\u001b[39m     prompt_mode=prompt_mode,\n\u001b[32m    192\u001b[39m     safe_prompt=safe_prompt,\n\u001b[32m    193\u001b[39m )\n\u001b[32m    195\u001b[39m req = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m    196\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    197\u001b[39m     path=\u001b[33m\"\u001b[39m\u001b[33m/v1/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    211\u001b[39m     timeout_ms=timeout_ms,\n\u001b[32m    212\u001b[39m )\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retries == UNSET:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\COM-NMOIM\\miniforge3\\envs\\graph-module\\Lib\\site-packages\\mistralai\\utils\\serializers.py:206\u001b[39m, in \u001b[36mget_pydantic_model\u001b[39m\u001b[34m(data, typ)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_pydantic_model\u001b[39m(data: Any, typ: Any) -> Any:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _contains_pydantic_model(data):\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munmarshal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\COM-NMOIM\\miniforge3\\envs\\graph-module\\Lib\\site-packages\\mistralai\\utils\\serializers.py:147\u001b[39m, in \u001b[36munmarshal\u001b[39m\u001b[34m(val, typ)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munmarshal\u001b[39m(val, typ: Any) -> Any:\n\u001b[32m    141\u001b[39m     unmarshaller = create_model(\n\u001b[32m    142\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnmarshaller\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    143\u001b[39m         body=(typ, ...),\n\u001b[32m    144\u001b[39m         __config__=ConfigDict(populate_by_name=\u001b[38;5;28;01mTrue\u001b[39;00m, arbitrary_types_allowed=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    145\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     m = \u001b[43munmarshaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m     \u001b[38;5;66;03m# pyright: ignore[reportAttributeAccessIssue]\u001b[39;00m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m m.body\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\COM-NMOIM\\miniforge3\\envs\\graph-module\\Lib\\site-packages\\pydantic\\main.py:214\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    213\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    216\u001b[39m     warnings.warn(\n\u001b[32m    217\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    220\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    221\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 3 validation errors for Unmarshaller\nbody.0.user.content.str\n  Input should be a valid string [type=string_type, input_value=[{'type': 'text', 'text':...6W1uAAAAAElFTkSuQmCC'}}], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type\nbody.0.user.content.list[tagged-union[ImageURLChunk,DocumentURLChunk,TextChunk,ReferenceChunk]].1.image_url.image_url.ImageURL.url\n  Field required [type=missing, input_value={'image_url': 'data:image...Nf6W1uAAAAAElFTkSuQmCC'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nbody.0.user.content.list[tagged-union[ImageURLChunk,DocumentURLChunk,TextChunk,ReferenceChunk]].1.image_url.image_url.str\n  Input should be a valid string [type=string_type, input_value={'image_url': 'data:image...Nf6W1uAAAAAElFTkSuQmCC'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type"
     ]
    }
   ],
   "source": [
    "response = client.chat.complete(\n",
    "    model = \"pixtral-12b-2409\",\n",
    "    messages = message_list\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-module",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
